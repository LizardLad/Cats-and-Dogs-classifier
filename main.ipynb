{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Cats and Dogs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adadelta, SGD\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation, Conv2D, MaxPooling2D, Flatten, Conv1D\n",
    "from keras.utils import np_utils\n",
    "from imutils import paths\n",
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(64, 64)):\n",
    "\t# resize the image to a fixed size, then flatten the image into\n",
    "\t# a list of raw pixel intensities\n",
    "\treturn cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] describing images...\n"
     ]
    }
   ],
   "source": [
    "train_test_split_data_done = False;\n",
    "\n",
    "if train_test_split_data_done == False:\n",
    "    # grab the list of images that we'll be describing\n",
    "    print(\"[INFO] describing images...\")\n",
    "    image_dataset = \"train/\"\n",
    "    imagePaths = list(paths.list_images(image_dataset))\n",
    "elif train_test_split_data_done == True:\n",
    "    train_dataset = \"train/\"\n",
    "    test_dataset = \"test/\"\n",
    "    # grab the list of images that we'll be describing\n",
    "    print(\"[INFO] describing training images...\")\n",
    "    trainimagePaths = list(paths.list_images(train_dataset))\n",
    "    print(\"[INFO] describing testing images...\")\n",
    "    testimagePaths = list(paths.list_images(test_dataset))\n",
    "else:\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data matrix and labels list\n",
    "trainingdata = []\n",
    "traininglabels = []\n",
    "testingdata = []\n",
    "testinglabels = []\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 1000/25001\n",
      "[INFO] processed 2000/25001\n",
      "[INFO] processed 3000/25001\n",
      "[INFO] processed 4000/25001\n",
      "[INFO] processed 5000/25001\n",
      "[INFO] processed 6000/25001\n",
      "[INFO] processed 7000/25001\n",
      "[INFO] processed 8000/25001\n",
      "[INFO] processed 9000/25001\n",
      "[INFO] processed 10000/25001\n",
      "[INFO] processed 11000/25001\n",
      "[INFO] processed 12000/25001\n",
      "[INFO] processed 13000/25001\n",
      "[INFO] processed 14000/25001\n",
      "[INFO] processed 15000/25001\n",
      "[INFO] processed 16000/25001\n",
      "[INFO] processed 17000/25001\n",
      "[INFO] processed 18000/25001\n",
      "[INFO] processed 19000/25001\n",
      "[INFO] processed 20000/25001\n",
      "[INFO] processed 21000/25001\n",
      "[INFO] processed 22000/25001\n",
      "[INFO] processed 23000/25001\n",
      "[INFO] processed 24000/25001\n",
      "[INFO] processed 25000/25001\n"
     ]
    }
   ],
   "source": [
    "# loop over the input images\n",
    "if train_test_split_data_done == False:\n",
    "    for (i, imagePath) in enumerate(imagePaths):\n",
    "        # load the image and extract the class label (assuming that our\n",
    "        # path as the format: /path/to/dataset/{class}.{image_num}.jpg\n",
    "        image = cv2.imread(imagePath)\n",
    "        label = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
    "\n",
    "        # construct a feature vector raw pixel intensities, then update\n",
    "        # the data matrix and labels list\n",
    "        features = image_to_feature_vector(image)\n",
    "        data.append(features)\n",
    "        labels.append(label)\n",
    "    \n",
    "        # show an update every 1,000 images\n",
    "        if i > 0 and i % 1000 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(imagePaths)))\n",
    "\n",
    "    # encode the labels, converting them from strings to integers\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "\n",
    "elif train_test_split_data_done == True:\n",
    "    for i, trainimagePath in enumerate(trainimagePaths):\n",
    "        # load the image and extract the class label (assuming that our\n",
    "        # path as the format: /path/to/dataset/{class}.{image_num}.jpg\n",
    "        trainingimage = cv2.imread(trainimagePath)\n",
    "        traininglabel = trainimagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
    "        \n",
    "        # construct a feature vector raw pixel intensities, then update\n",
    "        # the data matrix and labels list\n",
    "        trainingfeatures = image_to_feature_vector(trainingimage)\n",
    "        trainingdata.append(trainingfeatures)\n",
    "        traininglabels.append(traininglabel)\n",
    "        \n",
    "        # show an update every 1,000 images\n",
    "        if i > 0 and i % 1000 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(trainimagePaths)))\n",
    "            \n",
    "    # encode the labels, converting them from strings to integers\n",
    "    le = LabelEncoder()\n",
    "    traininglabels = le.fit_transform(traininglabels)\n",
    "    \n",
    "    for i, testimagePath in enumerate(testimagePaths):\n",
    "        # load the image and extract the class label (assuming that our\n",
    "        # path as the format: /path/to/dataset/{class}.{image_num}.jpg\n",
    "        testingimage = cv2.imread(testimagePath)\n",
    "        testinglabel = testimagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
    "        \n",
    "        # construct a feature vector raw pixel intensities, then update\n",
    "        # the data matrix and labels list\n",
    "        testingfeatures = image_to_feature_vector(testingimage)\n",
    "        testingdata.append(testingfeatures)\n",
    "        testinglabels.append(testinglabel)\n",
    "\n",
    "        # show an update every 100 images\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(testimagePaths)))\n",
    "\n",
    "    # encode the labels, converting them from strings to integers\n",
    "    le = LabelEncoder()\n",
    "    testinglabels = le.fit_transform(testinglabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the input image pixels to the range [0, 1], then transform\n",
    "# the labels into vectors in the range [0, num_classes] -- this\n",
    "# generates a vector for each label where the index of the label\n",
    "# is set to `1` and all other entries to `0`\n",
    "if train_test_split_data_done == True:\n",
    "    trainingdata = np.array(trainingdata) / 255.0\n",
    "    traininglabels = np_utils.to_categorical(traininglabels, 2)\n",
    "    testingdata = np.array(testingdata) / 255.0\n",
    "    testinglabels = np_utils.to_categorical(testinglabels, 2)\n",
    "        \n",
    "elif train_test_split_data_done == False:\n",
    "    data = np.array(data) / 255.0\n",
    "    labels = np_utils.to_categorical(labels, 2)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] constructing training/testing split...\n"
     ]
    }
   ],
   "source": [
    "if train_test_split_data_done == False:\n",
    "    # partition the data into training and testing splits, using 75%\n",
    "    # of the data for training and the remaining 25% for testing\n",
    "    print(\"[INFO] constructing training/testing split...\")\n",
    "    (trainData, testData, trainLabels, testLabels) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "elif train_test_split_data_done == True:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "\n",
    "if load_model == False:\n",
    "# define the architecture of the network\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3), padding='same'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    #model.add(Dense(128, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
    "    model.add(Dropout(0.1))\n",
    "    #model.add(Dense(32, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "elif load_model == True:\n",
    "    #load json and create model\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    #load weights into new model\n",
    "    model.load_weights(\"model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               2097280   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,125,058\n",
      "Trainable params: 2,125,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 13125 samples, validate on 5625 samples\n",
      "Epoch 1/350\n",
      "13125/13125 [==============================] - 11s 847us/step - loss: 0.6942 - acc: 0.4987 - val_loss: 0.6936 - val_acc: 0.4956\n",
      "Epoch 2/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6940 - acc: 0.4969 - val_loss: 0.6935 - val_acc: 0.4969\n",
      "Epoch 3/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6936 - acc: 0.5038 - val_loss: 0.6935 - val_acc: 0.4985\n",
      "Epoch 4/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6931 - acc: 0.5050 - val_loss: 0.6935 - val_acc: 0.4985\n",
      "Epoch 5/350\n",
      "13125/13125 [==============================] - 8s 572us/step - loss: 0.6937 - acc: 0.5072 - val_loss: 0.6935 - val_acc: 0.4988\n",
      "Epoch 6/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6936 - acc: 0.5064 - val_loss: 0.6935 - val_acc: 0.5003\n",
      "Epoch 7/350\n",
      "13125/13125 [==============================] - 7s 571us/step - loss: 0.6937 - acc: 0.5032 - val_loss: 0.6934 - val_acc: 0.5003\n",
      "Epoch 8/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6937 - acc: 0.5006 - val_loss: 0.6934 - val_acc: 0.5013\n",
      "Epoch 9/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6935 - acc: 0.5040 - val_loss: 0.6934 - val_acc: 0.5012\n",
      "Epoch 10/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6931 - acc: 0.5084 - val_loss: 0.6934 - val_acc: 0.5031\n",
      "Epoch 11/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6936 - acc: 0.5026 - val_loss: 0.6933 - val_acc: 0.5029\n",
      "Epoch 12/350\n",
      "13125/13125 [==============================] - 8s 573us/step - loss: 0.6935 - acc: 0.5068 - val_loss: 0.6933 - val_acc: 0.5038\n",
      "Epoch 13/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6935 - acc: 0.5003 - val_loss: 0.6933 - val_acc: 0.5038\n",
      "Epoch 14/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6932 - acc: 0.5088 - val_loss: 0.6933 - val_acc: 0.5032\n",
      "Epoch 15/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6942 - acc: 0.4982 - val_loss: 0.6932 - val_acc: 0.5049\n",
      "Epoch 16/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6936 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.5044\n",
      "Epoch 17/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6933 - acc: 0.5052 - val_loss: 0.6932 - val_acc: 0.5054\n",
      "Epoch 18/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6936 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5061\n",
      "Epoch 19/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6937 - acc: 0.4994 - val_loss: 0.6931 - val_acc: 0.5065\n",
      "Epoch 20/350\n",
      "13125/13125 [==============================] - 8s 572us/step - loss: 0.6928 - acc: 0.5074 - val_loss: 0.6931 - val_acc: 0.5077\n",
      "Epoch 21/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6935 - acc: 0.5042 - val_loss: 0.6931 - val_acc: 0.5083\n",
      "Epoch 22/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6935 - acc: 0.5050 - val_loss: 0.6931 - val_acc: 0.5083\n",
      "Epoch 23/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6932 - acc: 0.5065 - val_loss: 0.6930 - val_acc: 0.5093\n",
      "Epoch 24/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6936 - acc: 0.5035 - val_loss: 0.6930 - val_acc: 0.5104\n",
      "Epoch 25/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6939 - acc: 0.5032 - val_loss: 0.6930 - val_acc: 0.5108\n",
      "Epoch 26/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6929 - acc: 0.5092 - val_loss: 0.6930 - val_acc: 0.5113\n",
      "Epoch 27/350\n",
      "13125/13125 [==============================] - 7s 557us/step - loss: 0.6933 - acc: 0.5016 - val_loss: 0.6930 - val_acc: 0.5109\n",
      "Epoch 28/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6932 - acc: 0.5070 - val_loss: 0.6929 - val_acc: 0.5116\n",
      "Epoch 29/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6931 - acc: 0.5102 - val_loss: 0.6929 - val_acc: 0.5113\n",
      "Epoch 30/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6928 - acc: 0.5133 - val_loss: 0.6929 - val_acc: 0.5109\n",
      "Epoch 31/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6930 - acc: 0.5083 - val_loss: 0.6929 - val_acc: 0.5113\n",
      "Epoch 32/350\n",
      "13125/13125 [==============================] - 7s 570us/step - loss: 0.6927 - acc: 0.5103 - val_loss: 0.6928 - val_acc: 0.5118\n",
      "Epoch 33/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6929 - acc: 0.5112 - val_loss: 0.6928 - val_acc: 0.5127\n",
      "Epoch 34/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6929 - acc: 0.5037 - val_loss: 0.6928 - val_acc: 0.5138\n",
      "Epoch 35/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6931 - acc: 0.5099 - val_loss: 0.6928 - val_acc: 0.5134\n",
      "Epoch 36/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6934 - acc: 0.5056 - val_loss: 0.6927 - val_acc: 0.5134\n",
      "Epoch 37/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6931 - acc: 0.5056 - val_loss: 0.6927 - val_acc: 0.5134\n",
      "Epoch 38/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6932 - acc: 0.5045 - val_loss: 0.6927 - val_acc: 0.5141\n",
      "Epoch 39/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6922 - acc: 0.5136 - val_loss: 0.6927 - val_acc: 0.5148\n",
      "Epoch 40/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6927 - acc: 0.5105 - val_loss: 0.6926 - val_acc: 0.5154\n",
      "Epoch 41/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6934 - acc: 0.5006 - val_loss: 0.6926 - val_acc: 0.5157\n",
      "Epoch 42/350\n",
      "13125/13125 [==============================] - 7s 562us/step - loss: 0.6933 - acc: 0.5022 - val_loss: 0.6926 - val_acc: 0.5148\n",
      "Epoch 43/350\n",
      "13125/13125 [==============================] - 7s 560us/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6926 - val_acc: 0.5154\n",
      "Epoch 44/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6932 - acc: 0.5036 - val_loss: 0.6926 - val_acc: 0.5159\n",
      "Epoch 45/350\n",
      "13125/13125 [==============================] - 7s 570us/step - loss: 0.6926 - acc: 0.5076 - val_loss: 0.6925 - val_acc: 0.5168\n",
      "Epoch 46/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6927 - acc: 0.5096 - val_loss: 0.6925 - val_acc: 0.5168\n",
      "Epoch 47/350\n",
      "13125/13125 [==============================] - 7s 562us/step - loss: 0.6925 - acc: 0.5131 - val_loss: 0.6925 - val_acc: 0.5172\n",
      "Epoch 48/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6929 - acc: 0.5112 - val_loss: 0.6925 - val_acc: 0.5188\n",
      "Epoch 49/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6929 - acc: 0.5112 - val_loss: 0.6924 - val_acc: 0.5189\n",
      "Epoch 50/350\n",
      "13125/13125 [==============================] - 7s 570us/step - loss: 0.6929 - acc: 0.5090 - val_loss: 0.6924 - val_acc: 0.5184\n",
      "Epoch 51/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6925 - acc: 0.5160 - val_loss: 0.6924 - val_acc: 0.5186\n",
      "Epoch 52/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6929 - acc: 0.5077 - val_loss: 0.6924 - val_acc: 0.5188\n",
      "Epoch 53/350\n",
      "13125/13125 [==============================] - 7s 570us/step - loss: 0.6928 - acc: 0.5094 - val_loss: 0.6923 - val_acc: 0.5188\n",
      "Epoch 54/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6924 - acc: 0.5157 - val_loss: 0.6923 - val_acc: 0.5195\n",
      "Epoch 55/350\n",
      "13125/13125 [==============================] - 7s 560us/step - loss: 0.6927 - acc: 0.5149 - val_loss: 0.6923 - val_acc: 0.5200\n",
      "Epoch 56/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6927 - acc: 0.5087 - val_loss: 0.6923 - val_acc: 0.5214\n",
      "Epoch 57/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6926 - acc: 0.5144 - val_loss: 0.6922 - val_acc: 0.5207\n",
      "Epoch 58/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6928 - acc: 0.5109 - val_loss: 0.6922 - val_acc: 0.5218\n",
      "Epoch 59/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6926 - acc: 0.5167 - val_loss: 0.6922 - val_acc: 0.5223\n",
      "Epoch 60/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6927 - acc: 0.5088 - val_loss: 0.6922 - val_acc: 0.5234\n",
      "Epoch 61/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6925 - acc: 0.5076 - val_loss: 0.6922 - val_acc: 0.5239\n",
      "Epoch 62/350\n",
      "13125/13125 [==============================] - 7s 560us/step - loss: 0.6920 - acc: 0.5138 - val_loss: 0.6921 - val_acc: 0.5234\n",
      "Epoch 63/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6928 - acc: 0.5049 - val_loss: 0.6921 - val_acc: 0.5230\n",
      "Epoch 64/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6925 - acc: 0.5085 - val_loss: 0.6921 - val_acc: 0.5236\n",
      "Epoch 65/350\n",
      "13125/13125 [==============================] - 7s 558us/step - loss: 0.6927 - acc: 0.5131 - val_loss: 0.6921 - val_acc: 0.5239\n",
      "Epoch 66/350\n",
      "13125/13125 [==============================] - 8s 572us/step - loss: 0.6926 - acc: 0.5162 - val_loss: 0.6920 - val_acc: 0.5243\n",
      "Epoch 67/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6918 - acc: 0.5166 - val_loss: 0.6920 - val_acc: 0.5253\n",
      "Epoch 68/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6926 - acc: 0.5160 - val_loss: 0.6920 - val_acc: 0.5253\n",
      "Epoch 69/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6926 - acc: 0.5090 - val_loss: 0.6920 - val_acc: 0.5248\n",
      "Epoch 70/350\n",
      "13125/13125 [==============================] - 8s 573us/step - loss: 0.6924 - acc: 0.5074 - val_loss: 0.6920 - val_acc: 0.5250\n",
      "Epoch 71/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6925 - acc: 0.5139 - val_loss: 0.6919 - val_acc: 0.5262\n",
      "Epoch 72/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6918 - acc: 0.5216 - val_loss: 0.6919 - val_acc: 0.5266\n",
      "Epoch 73/350\n",
      "13125/13125 [==============================] - 7s 570us/step - loss: 0.6924 - acc: 0.5154 - val_loss: 0.6919 - val_acc: 0.5268\n",
      "Epoch 74/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6926 - acc: 0.5141 - val_loss: 0.6919 - val_acc: 0.5266\n",
      "Epoch 75/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6918 - acc: 0.5209 - val_loss: 0.6918 - val_acc: 0.5268\n",
      "Epoch 76/350\n",
      "13125/13125 [==============================] - 7s 560us/step - loss: 0.6920 - acc: 0.5160 - val_loss: 0.6918 - val_acc: 0.5269\n",
      "Epoch 77/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6925 - acc: 0.5134 - val_loss: 0.6918 - val_acc: 0.5269\n",
      "Epoch 78/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6919 - acc: 0.5151 - val_loss: 0.6918 - val_acc: 0.5282\n",
      "Epoch 79/350\n",
      "13125/13125 [==============================] - 8s 572us/step - loss: 0.6921 - acc: 0.5175 - val_loss: 0.6918 - val_acc: 0.5278\n",
      "Epoch 80/350\n",
      "13125/13125 [==============================] - 7s 562us/step - loss: 0.6921 - acc: 0.5184 - val_loss: 0.6917 - val_acc: 0.5284\n",
      "Epoch 81/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6921 - acc: 0.5171 - val_loss: 0.6917 - val_acc: 0.5285\n",
      "Epoch 82/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6923 - acc: 0.5122 - val_loss: 0.6917 - val_acc: 0.5282\n",
      "Epoch 83/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6925 - acc: 0.5086 - val_loss: 0.6917 - val_acc: 0.5300\n",
      "Epoch 84/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6923 - acc: 0.5128 - val_loss: 0.6916 - val_acc: 0.5303\n",
      "Epoch 85/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6924 - acc: 0.5101 - val_loss: 0.6916 - val_acc: 0.5305\n",
      "Epoch 86/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6917 - acc: 0.5228 - val_loss: 0.6916 - val_acc: 0.5307\n",
      "Epoch 87/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6922 - acc: 0.5104 - val_loss: 0.6916 - val_acc: 0.5303\n",
      "Epoch 88/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6921 - acc: 0.5134 - val_loss: 0.6916 - val_acc: 0.5307\n",
      "Epoch 89/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6920 - acc: 0.5173 - val_loss: 0.6915 - val_acc: 0.5310\n",
      "Epoch 90/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6920 - acc: 0.5163 - val_loss: 0.6915 - val_acc: 0.5310\n",
      "Epoch 91/350\n",
      "13125/13125 [==============================] - 7s 560us/step - loss: 0.6921 - acc: 0.5182 - val_loss: 0.6915 - val_acc: 0.5319\n",
      "Epoch 92/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6925 - acc: 0.5144 - val_loss: 0.6915 - val_acc: 0.5323\n",
      "Epoch 93/350\n",
      "13125/13125 [==============================] - 7s 571us/step - loss: 0.6915 - acc: 0.5203 - val_loss: 0.6914 - val_acc: 0.5328\n",
      "Epoch 94/350\n",
      "13125/13125 [==============================] - 7s 560us/step - loss: 0.6918 - acc: 0.5210 - val_loss: 0.6914 - val_acc: 0.5326\n",
      "Epoch 95/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6925 - acc: 0.5147 - val_loss: 0.6914 - val_acc: 0.5337\n",
      "Epoch 96/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6916 - acc: 0.5178 - val_loss: 0.6914 - val_acc: 0.5348\n",
      "Epoch 97/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6916 - acc: 0.5191 - val_loss: 0.6913 - val_acc: 0.5356\n",
      "Epoch 98/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6921 - acc: 0.5199 - val_loss: 0.6913 - val_acc: 0.5351\n",
      "Epoch 99/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6924 - acc: 0.5117 - val_loss: 0.6913 - val_acc: 0.5353\n",
      "Epoch 100/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6920 - acc: 0.5170 - val_loss: 0.6913 - val_acc: 0.5358\n",
      "Epoch 101/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6920 - acc: 0.5202 - val_loss: 0.6913 - val_acc: 0.5358\n",
      "Epoch 102/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6914 - acc: 0.5163 - val_loss: 0.6912 - val_acc: 0.5364\n",
      "Epoch 103/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6913 - acc: 0.5256 - val_loss: 0.6912 - val_acc: 0.5369\n",
      "Epoch 104/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13125/13125 [==============================] - 7s 570us/step - loss: 0.6918 - acc: 0.5153 - val_loss: 0.6912 - val_acc: 0.5364\n",
      "Epoch 105/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6913 - acc: 0.5215 - val_loss: 0.6912 - val_acc: 0.5365\n",
      "Epoch 106/350\n",
      "13125/13125 [==============================] - 7s 570us/step - loss: 0.6911 - acc: 0.5225 - val_loss: 0.6911 - val_acc: 0.5365\n",
      "Epoch 107/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6915 - acc: 0.5196 - val_loss: 0.6911 - val_acc: 0.5371\n",
      "Epoch 108/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6915 - acc: 0.5230 - val_loss: 0.6911 - val_acc: 0.5381\n",
      "Epoch 109/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6918 - acc: 0.5161 - val_loss: 0.6911 - val_acc: 0.5387\n",
      "Epoch 110/350\n",
      "13125/13125 [==============================] - 7s 571us/step - loss: 0.6918 - acc: 0.5168 - val_loss: 0.6911 - val_acc: 0.5388\n",
      "Epoch 111/350\n",
      "13125/13125 [==============================] - 7s 571us/step - loss: 0.6907 - acc: 0.5302 - val_loss: 0.6910 - val_acc: 0.5392\n",
      "Epoch 112/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6913 - acc: 0.5200 - val_loss: 0.6910 - val_acc: 0.5396\n",
      "Epoch 113/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6914 - acc: 0.5235 - val_loss: 0.6910 - val_acc: 0.5394\n",
      "Epoch 114/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6919 - acc: 0.5218 - val_loss: 0.6910 - val_acc: 0.5394\n",
      "Epoch 115/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6913 - acc: 0.5221 - val_loss: 0.6909 - val_acc: 0.5390\n",
      "Epoch 116/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6920 - acc: 0.5192 - val_loss: 0.6909 - val_acc: 0.5392\n",
      "Epoch 117/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6913 - acc: 0.5221 - val_loss: 0.6909 - val_acc: 0.5396\n",
      "Epoch 118/350\n",
      "13125/13125 [==============================] - 8s 573us/step - loss: 0.6916 - acc: 0.5197 - val_loss: 0.6909 - val_acc: 0.5394\n",
      "Epoch 119/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6913 - acc: 0.5211 - val_loss: 0.6908 - val_acc: 0.5394\n",
      "Epoch 120/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6913 - acc: 0.5177 - val_loss: 0.6908 - val_acc: 0.5399\n",
      "Epoch 121/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6915 - acc: 0.5214 - val_loss: 0.6908 - val_acc: 0.5397\n",
      "Epoch 122/350\n",
      "13125/13125 [==============================] - 7s 570us/step - loss: 0.6911 - acc: 0.5275 - val_loss: 0.6908 - val_acc: 0.5406\n",
      "Epoch 123/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6914 - acc: 0.5218 - val_loss: 0.6907 - val_acc: 0.5408\n",
      "Epoch 124/350\n",
      "13125/13125 [==============================] - 8s 572us/step - loss: 0.6908 - acc: 0.5291 - val_loss: 0.6907 - val_acc: 0.5404\n",
      "Epoch 125/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6912 - acc: 0.5288 - val_loss: 0.6907 - val_acc: 0.5413\n",
      "Epoch 126/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6913 - acc: 0.5209 - val_loss: 0.6907 - val_acc: 0.5406\n",
      "Epoch 127/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6911 - acc: 0.5278 - val_loss: 0.6906 - val_acc: 0.5413\n",
      "Epoch 128/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6913 - acc: 0.5204 - val_loss: 0.6906 - val_acc: 0.5408\n",
      "Epoch 129/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6915 - acc: 0.5182 - val_loss: 0.6906 - val_acc: 0.5424\n",
      "Epoch 130/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6909 - acc: 0.5272 - val_loss: 0.6906 - val_acc: 0.5424\n",
      "Epoch 131/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6914 - acc: 0.5204 - val_loss: 0.6905 - val_acc: 0.5428\n",
      "Epoch 132/350\n",
      "13125/13125 [==============================] - 7s 562us/step - loss: 0.6917 - acc: 0.5169 - val_loss: 0.6905 - val_acc: 0.5424\n",
      "Epoch 133/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6908 - acc: 0.5283 - val_loss: 0.6905 - val_acc: 0.5429\n",
      "Epoch 134/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6914 - acc: 0.5258 - val_loss: 0.6905 - val_acc: 0.5431\n",
      "Epoch 135/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6909 - acc: 0.5241 - val_loss: 0.6904 - val_acc: 0.5438\n",
      "Epoch 136/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6915 - acc: 0.5198 - val_loss: 0.6904 - val_acc: 0.5438\n",
      "Epoch 137/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6909 - acc: 0.5236 - val_loss: 0.6904 - val_acc: 0.5436\n",
      "Epoch 138/350\n",
      "13125/13125 [==============================] - 7s 557us/step - loss: 0.6908 - acc: 0.5253 - val_loss: 0.6904 - val_acc: 0.5440\n",
      "Epoch 139/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6912 - acc: 0.5244 - val_loss: 0.6903 - val_acc: 0.5442\n",
      "Epoch 140/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6913 - acc: 0.5240 - val_loss: 0.6903 - val_acc: 0.5451\n",
      "Epoch 141/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6911 - acc: 0.5247 - val_loss: 0.6903 - val_acc: 0.5456\n",
      "Epoch 142/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6909 - acc: 0.5228 - val_loss: 0.6903 - val_acc: 0.5460\n",
      "Epoch 143/350\n",
      "13125/13125 [==============================] - 7s 570us/step - loss: 0.6909 - acc: 0.5276 - val_loss: 0.6902 - val_acc: 0.5460\n",
      "Epoch 144/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6908 - acc: 0.5266 - val_loss: 0.6902 - val_acc: 0.5474\n",
      "Epoch 145/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6907 - acc: 0.5242 - val_loss: 0.6902 - val_acc: 0.5479\n",
      "Epoch 146/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6904 - acc: 0.5282 - val_loss: 0.6902 - val_acc: 0.5477\n",
      "Epoch 147/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6905 - acc: 0.5317 - val_loss: 0.6901 - val_acc: 0.5472\n",
      "Epoch 148/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6907 - acc: 0.5275 - val_loss: 0.6901 - val_acc: 0.5476\n",
      "Epoch 149/350\n",
      "13125/13125 [==============================] - 7s 562us/step - loss: 0.6908 - acc: 0.5322 - val_loss: 0.6901 - val_acc: 0.5468\n",
      "Epoch 150/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6905 - acc: 0.5317 - val_loss: 0.6901 - val_acc: 0.5474\n",
      "Epoch 151/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6905 - acc: 0.5266 - val_loss: 0.6900 - val_acc: 0.5474\n",
      "Epoch 152/350\n",
      "13125/13125 [==============================] - 7s 570us/step - loss: 0.6906 - acc: 0.5314 - val_loss: 0.6900 - val_acc: 0.5476\n",
      "Epoch 153/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6909 - acc: 0.5264 - val_loss: 0.6900 - val_acc: 0.5479\n",
      "Epoch 154/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6906 - acc: 0.5291 - val_loss: 0.6900 - val_acc: 0.5476\n",
      "Epoch 155/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6901 - acc: 0.5334 - val_loss: 0.6899 - val_acc: 0.5476\n",
      "Epoch 156/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6911 - acc: 0.5259 - val_loss: 0.6899 - val_acc: 0.5474\n",
      "Epoch 157/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6909 - acc: 0.5269 - val_loss: 0.6899 - val_acc: 0.5476\n",
      "Epoch 158/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6907 - acc: 0.5281 - val_loss: 0.6899 - val_acc: 0.5474\n",
      "Epoch 159/350\n",
      "13125/13125 [==============================] - 7s 560us/step - loss: 0.6903 - acc: 0.5329 - val_loss: 0.6898 - val_acc: 0.5481\n",
      "Epoch 160/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6908 - acc: 0.5281 - val_loss: 0.6898 - val_acc: 0.5484\n",
      "Epoch 161/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6909 - acc: 0.5262 - val_loss: 0.6898 - val_acc: 0.5486\n",
      "Epoch 162/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6904 - acc: 0.5315 - val_loss: 0.6898 - val_acc: 0.5488\n",
      "Epoch 163/350\n",
      "13125/13125 [==============================] - 7s 571us/step - loss: 0.6906 - acc: 0.5309 - val_loss: 0.6897 - val_acc: 0.5488\n",
      "Epoch 164/350\n",
      "13125/13125 [==============================] - 7s 570us/step - loss: 0.6908 - acc: 0.5330 - val_loss: 0.6897 - val_acc: 0.5492\n",
      "Epoch 165/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6906 - acc: 0.5260 - val_loss: 0.6897 - val_acc: 0.5495\n",
      "Epoch 166/350\n",
      "13125/13125 [==============================] - 7s 570us/step - loss: 0.6894 - acc: 0.5390 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 167/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6901 - acc: 0.5332 - val_loss: 0.6896 - val_acc: 0.5497\n",
      "Epoch 168/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6903 - acc: 0.5343 - val_loss: 0.6896 - val_acc: 0.5499\n",
      "Epoch 169/350\n",
      "13125/13125 [==============================] - 7s 559us/step - loss: 0.6902 - acc: 0.5374 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 170/350\n",
      "13125/13125 [==============================] - 7s 562us/step - loss: 0.6902 - acc: 0.5352 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 171/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6904 - acc: 0.5304 - val_loss: 0.6895 - val_acc: 0.5504\n",
      "Epoch 172/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6903 - acc: 0.5304 - val_loss: 0.6895 - val_acc: 0.5506\n",
      "Epoch 173/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6903 - acc: 0.5262 - val_loss: 0.6895 - val_acc: 0.5506\n",
      "Epoch 174/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6901 - acc: 0.5380 - val_loss: 0.6895 - val_acc: 0.5508\n",
      "Epoch 175/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6899 - acc: 0.5327 - val_loss: 0.6895 - val_acc: 0.5515\n",
      "Epoch 176/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6903 - acc: 0.5348 - val_loss: 0.6894 - val_acc: 0.5518\n",
      "Epoch 177/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6901 - acc: 0.5381 - val_loss: 0.6894 - val_acc: 0.5524\n",
      "Epoch 178/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6899 - acc: 0.5350 - val_loss: 0.6894 - val_acc: 0.5522\n",
      "Epoch 179/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6902 - acc: 0.5287 - val_loss: 0.6894 - val_acc: 0.5529\n",
      "Epoch 180/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6906 - acc: 0.5301 - val_loss: 0.6893 - val_acc: 0.5527\n",
      "Epoch 181/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6903 - acc: 0.5288 - val_loss: 0.6893 - val_acc: 0.5525\n",
      "Epoch 182/350\n",
      "13125/13125 [==============================] - 7s 570us/step - loss: 0.6899 - acc: 0.5281 - val_loss: 0.6893 - val_acc: 0.5536\n",
      "Epoch 183/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6901 - acc: 0.5316 - val_loss: 0.6893 - val_acc: 0.5538\n",
      "Epoch 184/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6895 - acc: 0.5392 - val_loss: 0.6892 - val_acc: 0.5532\n",
      "Epoch 185/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6900 - acc: 0.5299 - val_loss: 0.6892 - val_acc: 0.5536\n",
      "Epoch 186/350\n",
      "13125/13125 [==============================] - 7s 571us/step - loss: 0.6905 - acc: 0.5256 - val_loss: 0.6892 - val_acc: 0.5540\n",
      "Epoch 187/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6902 - acc: 0.5291 - val_loss: 0.6892 - val_acc: 0.5550\n",
      "Epoch 188/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6901 - acc: 0.5360 - val_loss: 0.6891 - val_acc: 0.5557\n",
      "Epoch 189/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6902 - acc: 0.5302 - val_loss: 0.6891 - val_acc: 0.5564\n",
      "Epoch 190/350\n",
      "13125/13125 [==============================] - 7s 562us/step - loss: 0.6895 - acc: 0.5411 - val_loss: 0.6891 - val_acc: 0.5572\n",
      "Epoch 191/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6899 - acc: 0.5348 - val_loss: 0.6891 - val_acc: 0.5570\n",
      "Epoch 192/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6899 - acc: 0.5297 - val_loss: 0.6890 - val_acc: 0.5572\n",
      "Epoch 193/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6898 - acc: 0.5389 - val_loss: 0.6890 - val_acc: 0.5573\n",
      "Epoch 194/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6902 - acc: 0.5317 - val_loss: 0.6890 - val_acc: 0.5584\n",
      "Epoch 195/350\n",
      "13125/13125 [==============================] - 7s 558us/step - loss: 0.6903 - acc: 0.5340 - val_loss: 0.6890 - val_acc: 0.5582\n",
      "Epoch 196/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6899 - acc: 0.5345 - val_loss: 0.6889 - val_acc: 0.5568\n",
      "Epoch 197/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6895 - acc: 0.5397 - val_loss: 0.6889 - val_acc: 0.5579\n",
      "Epoch 198/350\n",
      "13125/13125 [==============================] - 7s 560us/step - loss: 0.6899 - acc: 0.5400 - val_loss: 0.6889 - val_acc: 0.5582\n",
      "Epoch 199/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6897 - acc: 0.5307 - val_loss: 0.6889 - val_acc: 0.5575\n",
      "Epoch 200/350\n",
      "13125/13125 [==============================] - 7s 560us/step - loss: 0.6897 - acc: 0.5400 - val_loss: 0.6888 - val_acc: 0.5577\n",
      "Epoch 201/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6902 - acc: 0.5288 - val_loss: 0.6888 - val_acc: 0.5577\n",
      "Epoch 202/350\n",
      "13125/13125 [==============================] - 7s 562us/step - loss: 0.6903 - acc: 0.5286 - val_loss: 0.6888 - val_acc: 0.5577\n",
      "Epoch 203/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6897 - acc: 0.5357 - val_loss: 0.6888 - val_acc: 0.5577\n",
      "Epoch 204/350\n",
      "13125/13125 [==============================] - 7s 560us/step - loss: 0.6888 - acc: 0.5413 - val_loss: 0.6887 - val_acc: 0.5584\n",
      "Epoch 205/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6900 - acc: 0.5333 - val_loss: 0.6887 - val_acc: 0.5584\n",
      "Epoch 206/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6900 - acc: 0.5291 - val_loss: 0.6887 - val_acc: 0.5582\n",
      "Epoch 207/350\n",
      "13125/13125 [==============================] - 7s 562us/step - loss: 0.6902 - acc: 0.5352 - val_loss: 0.6887 - val_acc: 0.5579\n",
      "Epoch 208/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6898 - acc: 0.5351 - val_loss: 0.6886 - val_acc: 0.5588\n",
      "Epoch 209/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6900 - acc: 0.5341 - val_loss: 0.6886 - val_acc: 0.5584\n",
      "Epoch 210/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6893 - acc: 0.5381 - val_loss: 0.6886 - val_acc: 0.5600\n",
      "Epoch 211/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6900 - acc: 0.5334 - val_loss: 0.6886 - val_acc: 0.5598\n",
      "Epoch 212/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6896 - acc: 0.5359 - val_loss: 0.6885 - val_acc: 0.5596\n",
      "Epoch 213/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6896 - acc: 0.5394 - val_loss: 0.6885 - val_acc: 0.5604\n",
      "Epoch 214/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6893 - acc: 0.5435 - val_loss: 0.6885 - val_acc: 0.5604\n",
      "Epoch 215/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6891 - acc: 0.5340 - val_loss: 0.6885 - val_acc: 0.5602\n",
      "Epoch 216/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6899 - acc: 0.5359 - val_loss: 0.6884 - val_acc: 0.5611\n",
      "Epoch 217/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6897 - acc: 0.5430 - val_loss: 0.6884 - val_acc: 0.5607\n",
      "Epoch 218/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6891 - acc: 0.5416 - val_loss: 0.6884 - val_acc: 0.5604\n",
      "Epoch 219/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6892 - acc: 0.5416 - val_loss: 0.6884 - val_acc: 0.5600\n",
      "Epoch 220/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6896 - acc: 0.5387 - val_loss: 0.6883 - val_acc: 0.5604\n",
      "Epoch 221/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6890 - acc: 0.5438 - val_loss: 0.6883 - val_acc: 0.5604\n",
      "Epoch 222/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6890 - acc: 0.5420 - val_loss: 0.6883 - val_acc: 0.5602\n",
      "Epoch 223/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6893 - acc: 0.5364 - val_loss: 0.6882 - val_acc: 0.5604\n",
      "Epoch 224/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6891 - acc: 0.5427 - val_loss: 0.6882 - val_acc: 0.5609\n",
      "Epoch 225/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6887 - acc: 0.5423 - val_loss: 0.6882 - val_acc: 0.5605\n",
      "Epoch 226/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6892 - acc: 0.5368 - val_loss: 0.6882 - val_acc: 0.5599\n",
      "Epoch 227/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6888 - acc: 0.5414 - val_loss: 0.6881 - val_acc: 0.5604\n",
      "Epoch 228/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6892 - acc: 0.5420 - val_loss: 0.6881 - val_acc: 0.5604\n",
      "Epoch 229/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6890 - acc: 0.5387 - val_loss: 0.6881 - val_acc: 0.5609\n",
      "Epoch 230/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6899 - acc: 0.5332 - val_loss: 0.6881 - val_acc: 0.5612\n",
      "Epoch 231/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6888 - acc: 0.5448 - val_loss: 0.6880 - val_acc: 0.5620\n",
      "Epoch 232/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6889 - acc: 0.5417 - val_loss: 0.6880 - val_acc: 0.5637\n",
      "Epoch 233/350\n",
      "13125/13125 [==============================] - 7s 558us/step - loss: 0.6895 - acc: 0.5398 - val_loss: 0.6880 - val_acc: 0.5632\n",
      "Epoch 234/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6885 - acc: 0.5475 - val_loss: 0.6879 - val_acc: 0.5627\n",
      "Epoch 235/350\n",
      "13125/13125 [==============================] - 7s 560us/step - loss: 0.6890 - acc: 0.5422 - val_loss: 0.6879 - val_acc: 0.5625\n",
      "Epoch 236/350\n",
      "13125/13125 [==============================] - 7s 558us/step - loss: 0.6894 - acc: 0.5413 - val_loss: 0.6879 - val_acc: 0.5623\n",
      "Epoch 237/350\n",
      "13125/13125 [==============================] - 7s 560us/step - loss: 0.6888 - acc: 0.5453 - val_loss: 0.6879 - val_acc: 0.5630\n",
      "Epoch 238/350\n",
      "13125/13125 [==============================] - 7s 562us/step - loss: 0.6887 - acc: 0.5477 - val_loss: 0.6878 - val_acc: 0.5628\n",
      "Epoch 239/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6882 - acc: 0.5462 - val_loss: 0.6878 - val_acc: 0.5630\n",
      "Epoch 240/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6889 - acc: 0.5389 - val_loss: 0.6878 - val_acc: 0.5636\n",
      "Epoch 241/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6884 - acc: 0.5473 - val_loss: 0.6878 - val_acc: 0.5636\n",
      "Epoch 242/350\n",
      "13125/13125 [==============================] - 7s 560us/step - loss: 0.6887 - acc: 0.5464 - val_loss: 0.6877 - val_acc: 0.5639\n",
      "Epoch 243/350\n",
      "13125/13125 [==============================] - 7s 562us/step - loss: 0.6887 - acc: 0.5431 - val_loss: 0.6877 - val_acc: 0.5641\n",
      "Epoch 244/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6891 - acc: 0.5405 - val_loss: 0.6877 - val_acc: 0.5646\n",
      "Epoch 245/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6893 - acc: 0.5365 - val_loss: 0.6877 - val_acc: 0.5639\n",
      "Epoch 246/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6888 - acc: 0.5428 - val_loss: 0.6876 - val_acc: 0.5664\n",
      "Epoch 247/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6888 - acc: 0.5432 - val_loss: 0.6876 - val_acc: 0.5659\n",
      "Epoch 248/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6889 - acc: 0.5367 - val_loss: 0.6876 - val_acc: 0.5655\n",
      "Epoch 249/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6885 - acc: 0.5374 - val_loss: 0.6875 - val_acc: 0.5655\n",
      "Epoch 250/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6888 - acc: 0.5454 - val_loss: 0.6875 - val_acc: 0.5659\n",
      "Epoch 251/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6887 - acc: 0.5448 - val_loss: 0.6875 - val_acc: 0.5655\n",
      "Epoch 252/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6882 - acc: 0.5486 - val_loss: 0.6875 - val_acc: 0.5657\n",
      "Epoch 253/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6893 - acc: 0.5384 - val_loss: 0.6874 - val_acc: 0.5664\n",
      "Epoch 254/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6883 - acc: 0.5423 - val_loss: 0.6874 - val_acc: 0.5668\n",
      "Epoch 255/350\n",
      "13125/13125 [==============================] - 7s 570us/step - loss: 0.6876 - acc: 0.5481 - val_loss: 0.6874 - val_acc: 0.5664\n",
      "Epoch 256/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6884 - acc: 0.5438 - val_loss: 0.6873 - val_acc: 0.5671\n",
      "Epoch 257/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6883 - acc: 0.5487 - val_loss: 0.6873 - val_acc: 0.5668\n",
      "Epoch 258/350\n",
      "13125/13125 [==============================] - 8s 572us/step - loss: 0.6882 - acc: 0.5469 - val_loss: 0.6873 - val_acc: 0.5671\n",
      "Epoch 259/350\n",
      "13125/13125 [==============================] - 7s 564us/step - loss: 0.6871 - acc: 0.5574 - val_loss: 0.6873 - val_acc: 0.5675\n",
      "Epoch 260/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6878 - acc: 0.5515 - val_loss: 0.6872 - val_acc: 0.5682\n",
      "Epoch 261/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6885 - acc: 0.5500 - val_loss: 0.6872 - val_acc: 0.5682\n",
      "Epoch 262/350\n",
      "13125/13125 [==============================] - 7s 562us/step - loss: 0.6878 - acc: 0.5493 - val_loss: 0.6872 - val_acc: 0.5682\n",
      "Epoch 263/350\n",
      "13125/13125 [==============================] - 7s 550us/step - loss: 0.6885 - acc: 0.5426 - val_loss: 0.6871 - val_acc: 0.5691\n",
      "Epoch 264/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6887 - acc: 0.5446 - val_loss: 0.6871 - val_acc: 0.5700\n",
      "Epoch 265/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6885 - acc: 0.5398 - val_loss: 0.6871 - val_acc: 0.5701\n",
      "Epoch 266/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6883 - acc: 0.5452 - val_loss: 0.6870 - val_acc: 0.5700\n",
      "Epoch 267/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6887 - acc: 0.5472 - val_loss: 0.6870 - val_acc: 0.5701\n",
      "Epoch 268/350\n",
      "13125/13125 [==============================] - 7s 563us/step - loss: 0.6882 - acc: 0.5438 - val_loss: 0.6870 - val_acc: 0.5703\n",
      "Epoch 269/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6888 - acc: 0.5471 - val_loss: 0.6870 - val_acc: 0.5705\n",
      "Epoch 270/350\n",
      "13125/13125 [==============================] - 7s 561us/step - loss: 0.6882 - acc: 0.5506 - val_loss: 0.6869 - val_acc: 0.5705\n",
      "Epoch 271/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6883 - acc: 0.5390 - val_loss: 0.6869 - val_acc: 0.5707\n",
      "Epoch 272/350\n",
      "13125/13125 [==============================] - 7s 558us/step - loss: 0.6882 - acc: 0.5445 - val_loss: 0.6869 - val_acc: 0.5698\n",
      "Epoch 273/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6878 - acc: 0.5509 - val_loss: 0.6868 - val_acc: 0.5694\n",
      "Epoch 274/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6884 - acc: 0.5467 - val_loss: 0.6868 - val_acc: 0.5694\n",
      "Epoch 275/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6880 - acc: 0.5463 - val_loss: 0.6868 - val_acc: 0.5700\n",
      "Epoch 276/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6886 - acc: 0.5435 - val_loss: 0.6868 - val_acc: 0.5700\n",
      "Epoch 277/350\n",
      "13125/13125 [==============================] - 7s 562us/step - loss: 0.6882 - acc: 0.5495 - val_loss: 0.6867 - val_acc: 0.5692\n",
      "Epoch 278/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6880 - acc: 0.5530 - val_loss: 0.6867 - val_acc: 0.5694\n",
      "Epoch 279/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6879 - acc: 0.5474 - val_loss: 0.6867 - val_acc: 0.5692\n",
      "Epoch 280/350\n",
      "13125/13125 [==============================] - 7s 566us/step - loss: 0.6874 - acc: 0.5522 - val_loss: 0.6866 - val_acc: 0.5694\n",
      "Epoch 281/350\n",
      "13125/13125 [==============================] - 7s 571us/step - loss: 0.6879 - acc: 0.5472 - val_loss: 0.6866 - val_acc: 0.5691\n",
      "Epoch 282/350\n",
      "13125/13125 [==============================] - 7s 569us/step - loss: 0.6874 - acc: 0.5530 - val_loss: 0.6866 - val_acc: 0.5691\n",
      "Epoch 283/350\n",
      "13125/13125 [==============================] - 7s 565us/step - loss: 0.6879 - acc: 0.5451 - val_loss: 0.6865 - val_acc: 0.5691\n",
      "Epoch 284/350\n",
      "13125/13125 [==============================] - 7s 567us/step - loss: 0.6873 - acc: 0.5489 - val_loss: 0.6865 - val_acc: 0.5691\n",
      "Epoch 285/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6872 - acc: 0.5505 - val_loss: 0.6865 - val_acc: 0.5701\n",
      "Epoch 286/350\n",
      "13125/13125 [==============================] - 7s 568us/step - loss: 0.6880 - acc: 0.5490 - val_loss: 0.6864 - val_acc: 0.5703\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00286: early stopping\n"
     ]
    }
   ],
   "source": [
    "should_train = True\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "if train_test_split_data_done == False:\n",
    "    if should_train == True:\n",
    "        # train the model using SGD\n",
    "        print(\"[INFO] compiling model...\")\n",
    "        sgd = SGD(lr=0.0001)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "        print(model.summary())\n",
    "\n",
    "        model.fit(trainData.reshape(18750, 64, 64, 3), trainLabels, epochs=175*2, batch_size=128, verbose=1, validation_split=0.3,\n",
    "                  callbacks=[EarlyStopping(monitor='val_acc', min_delta=0, patience=15, verbose=1, mode='max', baseline=None, restore_best_weights=True)])\n",
    "    else:\n",
    "        # Compile the model\n",
    "        print(\"[INFO] compiling model...\")\n",
    "        sgd = SGD(lr=0.01)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "\n",
    "elif train_test_split_data_done == True:\n",
    "    if should_train == True:\n",
    "        # train the model using SGD\n",
    "        print(\"[INFO] compiling model...\")\n",
    "        sgd = SGD(lr=0.0001)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "        model.fit(trainingdata, traininglabels, epochs=350, batch_size=256, verbose=1)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating on testing set...\n",
      "6251/6251 [==============================] - 1s 239us/step\n",
      "[INFO] loss=0.4550, accuracy: 78.7074%\n"
     ]
    }
   ],
   "source": [
    "should_test = True\n",
    "\n",
    "if train_test_split_data_done == False:\n",
    "    if should_test == True:\n",
    "        # show the accuracy on the testing set\n",
    "        print(\"[INFO] evaluating on testing set...\")\n",
    "        (loss, accuracy) = model.evaluate(testData.reshape(6251, 64, 64, 3), testLabels, batch_size=128, verbose=1)\n",
    "        print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "elif train_test_split_data_done == True:\n",
    "    if should_test == True:\n",
    "        # show the accuracy on the testing set\n",
    "        print(\"[INFO] evaluating on testing set...\")\n",
    "        (loss, accuracy) = model.evaluate(testingdata, testinglabels, batch_size=256, verbose=1)\n",
    "        print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))\n",
    "    else:\n",
    "        pass\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_save = True\n",
    "\n",
    "if model_save == True:\n",
    "\t# serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        model.save_weights(\"model.h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'string' has no attribute 'maketrans'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0d03ec12406c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"ynnjw ml rfc spj.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"abcdefghijklmnopqrstuvwxyz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cdefghijklmnopqrstuvwxyzab\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'string' has no attribute 'maketrans'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
